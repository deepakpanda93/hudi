{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4902a7a7-c239-4700-a95f-b4daadc74b5b",
   "metadata": {},
   "source": [
    "# Deep Dive into Hudi Metadata Table and Indexing Enhancements in 1.x, Including SQL-Based Index Management\n",
    "\n",
    "Welcome to this guide on the Hudi Metadata Table and its role in boosting performance. In a large-scale data lake, simply listing files can become a significant bottleneck. Hudi's Metadata Table is a powerful, self-managed Hudi table that tracks all file listings, partitions, and statistics, allowing for much faster queries and more efficient operations.\n",
    "\n",
    "In Hudi 1.x, these features have been further enhanced with the ability to manage indexes directly using SQL. This notebook will demonstrate:\n",
    "\n",
    "- ***What the Metadata Table is:*** We'll inspect the files that make up the Metadata Table.\n",
    "- ***The Performance Impact:*** We'll show how the Metadata Table speeds up file listing.\n",
    "- ***SQL-Based Index Management:*** We'll create, use, and drop indexes directly with SQL commands to optimize queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53e9c2-18d8-4d24-abbc-47b08cd98ffc",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "First, we begin by importing our necessary libraries and starting a SparkSession configured to work with Hudi and MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b507005d-b5a8-456a-bd5b-1b1f2f274e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab6d32-4503-49e9-ab2a-172a6f170b50",
   "metadata": {},
   "source": [
    "Now, let's start the SparkSession. We'll give it the app name 'HudiMetadataIndexing' and configure it to use our Hudi and MinIO settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9578a6df-9ba2-4956-ba1c-d282bf8041c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/22 12:02:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/22 12:02:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "spark = get_spark(\"HudiMetadataIndexing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7794052-d7e9-4de0-afbd-fad12b6f39e1",
   "metadata": {},
   "source": [
    "## Initial Table Creation\n",
    "We'll start with a simple dataset of ride data. This will be our main table, and we'll then explore its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedc4a7-8084-4420-b2ae-8b5f55ad5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_data = [\n",
    "    (\"2025-08-10 08:15:30\", \"uuid-001\", \"rider-A\", \"driver-X\", 18.50, \"new_york\"),\n",
    "    (\"2025-08-10 09:22:10\", \"uuid-002\", \"rider-B\", \"driver-Y\", 22.75, \"san_francisco\"),\n",
    "    (\"2025-08-10 10:05:45\", \"uuid-003\", \"rider-C\", \"driver-Z\", 14.60, \"chicago\")\n",
    "]\n",
    "initial_columns = [\"ts\", \"uuid\", \"rider\", \"driver\", \"fare\", \"city\"]\n",
    "initial_df = spark.createDataFrame(initial_data).toDF(*initial_columns)\n",
    "\n",
    "display(initial_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db4cdb-2180-419d-b4e0-066a15aac503",
   "metadata": {},
   "source": [
    "Now, let's create a Hudi table with a crucial configuration: ***\"hoodie.metadata.enable\": \"true\".*** This flag tells Hudi to maintain an internal Metadata Table, which will speed up our operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b63196-53e9-4360-87e1-c649ed534f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# WARNING: Unable to attach Serviceability Agent. Unable to attach even with module exceptions: [org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "table_name = \"rides_metadata_table\"\n",
    "base_path = \"s3a://warehouse/hudi-metadata\"\n",
    "\n",
    "hudi_conf = {\n",
    "    \"hoodie.table.name\": table_name,\n",
    "    \"hoodie.datasource.write.recordkey.field\": \"uuid\",\n",
    "    \"hoodie.datasource.write.table.type\": \"COPY_ON_WRITE\",\n",
    "    \"hoodie.datasource.write.precombine.field\": \"ts\",\n",
    "    \"hoodie.datasource.write.partitionpath.field\": \"city\",\n",
    "    \"hoodie.metadata.enable\": \"true\",\n",
    "    \"hoodie.datasource.hive_sync.enable\": \"true\",\n",
    "    \"hoodie.datasource.hive_sync.database\": \"default\",\n",
    "    \"hoodie.datasource.hive_sync.table\": table_name,\n",
    "    \"hoodie.datasource.hive_sync.metastore.uris\": \"thrift://hivemetastore:9083\",\n",
    "    \"hoodie.datasource.hive_sync.mode\": \"hms\",\n",
    "    \"hoodie.datasource.hive_sync.partition_extractor_class\": \"org.apache.hudi.hive.MultiPartKeysValueExtractor\"\n",
    "}\n",
    "\n",
    "initial_df.write.format(\"hudi\") \\\n",
    "    .options(**hudi_conf) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"{base_path}/{table_name}\")\n",
    "\n",
    "# Register a temp view to easily query the table\n",
    "spark.read.format(\"hudi\").load(f\"{base_path}/{table_name}\").createOrReplaceTempView(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab201e8-fbe8-4651-8e16-4557bd8be88b",
   "metadata": {},
   "source": [
    "## The Hudi Metadata Table: A Deeper Look\n",
    "\n",
    "Hudi employs a special internal metadata table within each dataset to track metadata information - such as file listings and column statistics, helping avoid costly file system scans and improving read/write efficiency.\n",
    "\n",
    "***Key Features of the Metadata Table:***\n",
    "- ***Scalable:*** Capable of scaling to large sizes, handling TBs of metadata efficiently.\n",
    "- ***Flexible:*** Supports multi-modal indexing, allowing enabling/disabling various index types dynamically.\n",
    "- ***Fast Lookups:*** Uses an SSTable-like base file format (HFile) for fast partial scans and selective column reads.\n",
    "\n",
    "***The metadata table holds auxiliary data like:***\n",
    "- File indices for efficient record location\n",
    "- Column statistics for data skipping\n",
    "- Bloom filters for quick membership tests\n",
    "- Record and secondary indexes to speed up queries\n",
    "\n",
    "Let's look at the file system of our newly created table. Here three directories with city names, are partitions containing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43b443-bd99-4298-b21d-e195f23a8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls(f\"{base_path}/{table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1b64e-0081-4c6e-b44f-41b9abd8125d",
   "metadata": {},
   "source": [
    "Now If you look inside a partition directory you will see following files. ***.hoodie_partition_metadata*** files store information about partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9e286-7920-42b7-bfc4-af4aa683fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls(f\"{base_path}/{table_name}/new_york\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2e674-5dfe-408f-8a27-1d186f0b7043",
   "metadata": {},
   "source": [
    "The .hoodie directory contains subdirectories that store metadata files. Notice the special ***.hoodie/metadata*** directory. This is the Metadata Table itself. The files inside are not human-readable but are critical for Hudi's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e27e9f-7122-4a87-a4a0-4f532a64a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the contents of the Hudi table's .hoodie directory\n",
    "ls(f\"{base_path}/{table_name}/.hoodie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a4d25-af72-41c3-8000-5c780cca0342",
   "metadata": {},
   "source": [
    "The output shows several key directories and files:\n",
    "\n",
    "- ***.aux, .index_defs, .temp:*** These folders store internal metadata and temporary files.\n",
    "- ***.schema:*** This folder stores schema information for the Hudi table which helps in schema evolution.\n",
    "- ***timeline:*** This directory contains all the files that make up the Hudi Timeline, which is a record of every transaction that has occurred on the table.\n",
    "- ***metadata:*** This is the Metadata Table. It is itself a Hudi table and contains the file-level metadata like partition paths, file listings, and commit information that allows Hudi to quickly find files without performing a full file system scan.\n",
    "- ***hoodie.properties:*** The main configuration file for the table, which holds settings like the table name, key fields, and partitioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58025316-b5fd-497d-bb8f-5b3350a6c765",
   "metadata": {},
   "source": [
    "Another crucial part of this metadata is the ***Hudi Timeline***, which consists of small files that log every change to the table. These meta-files follow the naming pattern below:\n",
    "\n",
    "[action timestamp].[action type].[action state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab26eb-b37e-4e88-a8ae-69a2280e1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the contents of the Hudi table's timeline directory\n",
    "ls(f\"{base_path}/{table_name}/.hoodie/timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58ff96-c416-4098-9a75-9265d4d2ae51",
   "metadata": {},
   "source": [
    "- An action timestamp is a unique, chronological identifier for each event, marking when it was scheduled.\n",
    "- An action type describes the operation that took place. Examples include commit or deltacommit for data changes, compaction or clean for maintenance, and savepoint or restore for recovery.\n",
    "- An action state shows the current status of the action. It can be requested (waiting to start), inflight (in progress), or commit (completed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161b9be-90b1-495c-9a77-034b4a51506e",
   "metadata": {},
   "source": [
    "## Indexing Enhancements in Hudi 1.x\n",
    "Hudi 1.x introduces an advanced indexing subsystem that generalizes index capabilities closer to those found in relational databases.\n",
    "\n",
    "Important Enhancements:\n",
    "- ***Secondary Indexes:*** Support for indexes on any secondary columns to speed up query filtering.\n",
    "- ***Expression-Based Indexes:*** Indexes on expressions or transformed columns, enabling advanced data skipping.\n",
    "- ***SQL-Based Index Management:*** Users can create and manage indexes using standard SQL DDL commands via Spark SQL.\n",
    "- ***Asynchronous Indexing:*** Indexes can be built asynchronously alongside ongoing writes, improving write throughput without blocking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e713216-a482-4da8-bb33-b1f3d81d6113",
   "metadata": {},
   "source": [
    "## SQL-Based Index Creation and Management\n",
    "With Hudi 1.x, you can create different types of indexes directly on the Metadata Table using SQL. These indexes further accelerate query performance, especially for filtering on specific columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b743ab-ba57-411c-8682-5a6522d95ea5",
   "metadata": {},
   "source": [
    "### Example Commands:\n",
    "\n",
    "- Enable record index (dependency for secondary index)\n",
    "=> SET hoodie.metadata.record.index.enable=true;\n",
    "\n",
    "- Create record index on primary key column (e.g., uuid)\n",
    "=> CREATE INDEX record_index ON hudi_table (uuid);\n",
    "\n",
    "- Create secondary index on 'rider' column\n",
    "=> CREATE INDEX idx_rider ON hudi_table (rider);\n",
    "\n",
    "- Create bloom filter index on 'driver' column\n",
    "=> CREATE INDEX idx_bloom_driver ON hudi_table USING bloom_filters(driver) OPTIONS(expr='identity');\n",
    "\n",
    "- Create expression-based column stats index on timestamp column\n",
    "=> CREATE INDEX idx_column_ts ON hudi_table USING column_stats(ts) OPTIONS(expr='from_unixtime', format='yyyy-MM-dd');\n",
    "\n",
    "- Drop indexes when no longer needed\n",
    "=> DROP INDEX record_index ON hudi_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a24e1-1d1b-4dbb-ac7f-3052abe39cab",
   "metadata": {},
   "source": [
    "### Practical Example Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace4895-b7b0-4037-8f8c-68b1514f542e",
   "metadata": {},
   "source": [
    "***1. Create a Spark SQL Table on Hudi Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0e1a0-fa2c-42a8-b260-12e4a8d345b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    " CREATE TABLE {table_name}\n",
    " USING hudi\n",
    " LOCATION '{base_path}/{table_name}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbac5b-6e47-4d97-b446-1046f2a47587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
